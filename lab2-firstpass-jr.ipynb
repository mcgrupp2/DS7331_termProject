{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"header_names = [\n    'age',\n    'class_worker',\n    'det_ind_code',\n    'det_occ_code',\n    'education',\n    'wage_per_hour',\n    'hs_college',\n    'marital_stat',\n    'major_ind_code',\n    'major_occ_code',\n    'race',\n    'hisp_origin',\n    'sex',\n    'union_member',\n    'unemp_reason',\n    'full_or_part_emp',\n    'capital_gains',\n    'capital_losses',\n    'stock_dividends',\n    'tax_filer_stat',\n    'region_prev_res',\n    'state_prev_res',\n    'det_hh_fam_stat',\n    'det_hh_summ',\n    'instance_weight', ## this field is not used as a feature\n    'mig_chg_msa',\n    'mig_chg_reg',\n    'mig_move_reg',\n    'mig_same',\n    'mig_prev_sunbelt',\n    'num_emp',\n    'fam_under_18',\n    'country_father',\n    'country_mother',\n    'country_self',\n    'citizenship',\n    'own_or_self',\n    'vet_question',\n    'vet_benefits',\n    'weeks_worked',\n    'year',\n    'income_50k',\n]\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df1=pd.read_csv(\"../input/ml1-project/census-income.data.csv\",header = None, names = header_names)\ndf2=pd.read_csv(\"../input/testset/census-income.test.csv\",header = None, names = header_names)\n\ndf = pd.concat([df1, df2]) #The test file, labeled so it can be merged with original \ndf.drop(columns = ['instance_weight'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create a new variable for classification based of if the person recieved a \n## college degree\nhiger_degrees = [\n    ' Bachelors degree(BA AB BS)', \n    ' Masters degree(MA MS MEng MEd MSW MBA)', \n    ' Prof school degree (MD DDS DVM LLB JD)',\n    ' Doctorate degree(PhD EdD)',\n]\n\ndf['graduated'] = 'no'\ndf.loc[df['education'].isin(higer_degrees), 'graduated'] = 'yes'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\ndf.head()\nlist(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"capital_gains\", y=\"age\", hue=\"income_50k\", alpha=.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"capital_losses\", y=\"age\", hue=\"income_50k\", alpha=.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"stock_dividends\", y=\"age\", hue=\"income_50k\", alpha=.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_keep=[\n    'age', \n    'education', \n    'race', \n    'sex', \n    'capital_gains', \n    'capital_losses', \n    'stock_dividends', \n    'tax_filer_stat', \n    'det_hh_summ', \n    'own_or_self', \n    'vet_benefits', \n    'weeks_worked',\n    'income_50k'\n]\n\ndf_trunc = df.loc[:,cols_to_keep]\n\ndf_trunc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_cols=['education', 'race', 'sex', 'tax_filer_stat', 'det_hh_summ']\n\ndf_trunc.loc[:,ind_cols].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform one-hot encoding \ntmp_df = pd.get_dummies(df_trunc.loc[:,ind_cols])\ndf_trunc=df_trunc.drop(['education', 'race', 'sex', 'tax_filer_stat', 'det_hh_summ'], axis=1)\ndf_trunc_ind = pd.concat((df_trunc,tmp_df),axis=1) # add back into the dataframe\n\nlist(df_trunc_ind.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n\n# NEED to make pipeline or columntransformer \n\nscaler = StandardScaler()\n\ndf_scaled = df_trunc_ind.copy()\n\ncols_to_scale = ['capital_gains', 'capital_losses', 'stock_dividends']\n\nfeatures = df_scaled[cols_to_scale]\n\nscaler = StandardScaler().fit(features.values)\n\nfeatures = scaler.transform(features.values)\n\ndf_scaled[cols_to_scale] = features\n\ndf_scaled.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in [\"own_or_self\", \"vet_benefits\", \"weeks_worked\", \"income_50k\"]:\n    df_scaled[col] = df_scaled[col].astype('category')\n    \ndf_scaled.info()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = df_scaled['income_50k']\n\nX = df_scaled.drop('income_50k', axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlr = LogisticRegression(max_iter=100000)\n\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nacc = accuracy_score(y_test, lr.predict(X_test))\nprint(\"{0:.1%} accuracy on test set.\".format(acc)) \n# print(dict(zip(X.columns, abs(lr.coef_[0]).round(2))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.svm import SVC\n# \n# svc = SVC()\n# \n# # Fit the model to the training data\n# svc.fit(X_train, y_train)\n# \n# # Calculate accuracy scores on both train and test data\n# accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n# accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n# \n# print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.feature_selection import RFE\n# # Create the RFE with a LogisticRegression estimator and 3 features to select\n# rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10, verbose=1)\n# \n# # Fits the eliminator to the data\n# rfe.fit(X_train, y_train)\n# \n# # Print the features and their ranking (high = dropped early on)\n# print(dict(zip(X.columns, rfe.ranking_)))\n# \n# # Print the features that are not eliminated\n# print(X.columns[rfe.support_])\n# \n# # Calculates the test set accuracy\n# acc = accuracy_score(y_test, rfe.predict(X_test))\n# print(\"{0:.1%} accuracy on test set.\".format(acc)) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}