{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Classification\n",
    "Group 2 Team Members:\n",
    "\n",
    "- Name 1: Aniketh Vankina\n",
    "- Name 2: Indy Dhillon \n",
    "- Name 3: Jason Rupp \n",
    "- Name 4: Suchismita Moharana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = [\n",
    "    'age',\n",
    "    'class_worker',\n",
    "    'det_ind_code',\n",
    "    'det_occ_code',\n",
    "    'education',\n",
    "    'wage_per_hour',\n",
    "    'hs_college',\n",
    "    'marital_stat',\n",
    "    'major_ind_code',\n",
    "    'major_occ_code',\n",
    "    'race',\n",
    "    'hisp_origin',\n",
    "    'sex',\n",
    "    'union_member',\n",
    "    'unemp_reason',\n",
    "    'full_or_part_emp',\n",
    "    'capital_gains',\n",
    "    'capital_losses',\n",
    "    'stock_dividends',\n",
    "    'tax_filer_stat',\n",
    "    'region_prev_res',\n",
    "    'state_prev_res',\n",
    "    'det_hh_fam_stat',\n",
    "    'det_hh_summ',\n",
    "    'instance_weight', ## this field is not used as a feature\n",
    "    'mig_chg_msa',\n",
    "    'mig_chg_reg',\n",
    "    'mig_move_reg',\n",
    "    'mig_same',\n",
    "    'mig_prev_sunbelt',\n",
    "    'num_emp',\n",
    "    'fam_under_18',\n",
    "    'country_father',\n",
    "    'country_mother',\n",
    "    'country_self',\n",
    "    'citizenship',\n",
    "    'own_or_self',\n",
    "    'vet_question',\n",
    "    'vet_benefits',\n",
    "    'weeks_worked',\n",
    "    'year',\n",
    "    'income_50k',\n",
    "]\n",
    "\n",
    "\n",
    "data_dir = os.path.join(pathlib.Path(os.getcwd()).parent, 'data')\n",
    "df = pd.read_csv(os.path.join(data_dir, 'census-income.data.csv'), header=None, names=header_names)\n",
    "df_test = pd.read_csv(os.path.join(data_dir, 'census-income.test.csv'), header=None, names=header_names)\n",
    "df = pd.concat([df,df_test]) ## the test file is also labelled so they can be merged\n",
    "df.drop(columns=['instance_weight']) ## not used for our analysis\n",
    "\n",
    "categorical_features = [\n",
    "    'class_worker',\n",
    "    'det_ind_code',\n",
    "    'det_occ_code',\n",
    "    'education',\n",
    "    'hs_college',\n",
    "    'marital_stat',\n",
    "    'major_ind_code',\n",
    "    'major_occ_code',\n",
    "    'race',\n",
    "    'hisp_origin',\n",
    "    'sex',\n",
    "    'union_member',\n",
    "    'unemp_reason',\n",
    "    'full_or_part_emp',\n",
    "    'tax_filer_stat',\n",
    "    'region_prev_res',\n",
    "    'state_prev_res',\n",
    "    'det_hh_fam_stat',\n",
    "    'det_hh_summ',\n",
    "    'mig_chg_msa',\n",
    "    'mig_chg_reg',\n",
    "    'mig_move_reg',\n",
    "    'mig_same',\n",
    "    'mig_prev_sunbelt',\n",
    "    'fam_under_18',\n",
    "    'country_father',\n",
    "    'country_mother',\n",
    "    'country_self',\n",
    "    'citizenship',\n",
    "    'own_or_self',\n",
    "    'vet_question',\n",
    "    'vet_benefits',\n",
    "    'year',\n",
    "]\n",
    "df[categorical_features] = df[categorical_features].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop columns not used in modelling\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        'region_prev_res',\n",
    "        'state_prev_res',\n",
    "        'det_hh_fam_stat',\n",
    "        'det_hh_summ',\n",
    "        'mig_chg_msa',\n",
    "        'mig_chg_reg',\n",
    "        'mig_move_reg',\n",
    "        'mig_same',\n",
    "        'mig_prev_sunbelt',\n",
    "        'country_father',\n",
    "        'country_mother',\n",
    "        'country_self',\n",
    "        'year',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 299285 entries, 0 to 99761\n",
      "Data columns (total 29 columns):\n",
      "age                 299285 non-null int64\n",
      "class_worker        299285 non-null category\n",
      "det_ind_code        299285 non-null category\n",
      "det_occ_code        299285 non-null category\n",
      "education           299285 non-null category\n",
      "wage_per_hour       299285 non-null int64\n",
      "hs_college          299285 non-null category\n",
      "marital_stat        299285 non-null category\n",
      "major_ind_code      299285 non-null category\n",
      "major_occ_code      299285 non-null category\n",
      "race                299285 non-null category\n",
      "hisp_origin         299285 non-null category\n",
      "sex                 299285 non-null category\n",
      "union_member        299285 non-null category\n",
      "unemp_reason        299285 non-null category\n",
      "full_or_part_emp    299285 non-null category\n",
      "capital_gains       299285 non-null int64\n",
      "capital_losses      299285 non-null int64\n",
      "stock_dividends     299285 non-null int64\n",
      "tax_filer_stat      299285 non-null category\n",
      "instance_weight     299285 non-null float64\n",
      "num_emp             299285 non-null int64\n",
      "fam_under_18        299285 non-null category\n",
      "citizenship         299285 non-null category\n",
      "own_or_self         299285 non-null category\n",
      "vet_question        299285 non-null category\n",
      "vet_benefits        299285 non-null category\n",
      "weeks_worked        299285 non-null int64\n",
      "income_50k          299285 non-null object\n",
      "dtypes: category(20), float64(1), int64(7), object(1)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# This is section one of the data processing, will be using the same data as shown in the minilab\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the dataset\n",
    "selection_df = df.sample(frac = .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(numeric_features, categorical_features):\n",
    "    ### Scale numerical, one hot categorical\n",
    "\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            #('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ]\n",
    "    )\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)]\n",
    "    )\n",
    "    preprocess_pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocess_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess the data\n",
    "numeric_features = selection_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features_income = selection_df.select_dtypes(include=['object','bool', 'category']).drop(['income_50k'], axis=1).columns\n",
    "X_selection_income = selection_df.drop('income_50k', axis=1)\n",
    "y_selection_income = selection_df['income_50k']\n",
    "preprocessor_income = preprocess_pipeline(numeric_features, categorical_features_income)\n",
    "X_selection_preprocessed_income = preprocessor_income.fit_transform(X_selection_income)\n",
    "\n",
    "higer_degrees = [\n",
    "    ' Bachelors degree(BA AB BS)', \n",
    "    ' Masters degree(MA MS MEng MEd MSW MBA)', \n",
    "    ' Prof school degree (MD DDS DVM LLB JD)',\n",
    "    ' Doctorate degree(PhD EdD)',\n",
    "]\n",
    "selection_df['graduated'] = 'no'\n",
    "selection_df.loc[selection_df['education'].isin(higer_degrees), 'graduated'] = 'yes'\n",
    "selection_df = selection_df.drop(['education'], axis=1)\n",
    "\n",
    "categorical_features_grad = selection_df.select_dtypes(include=['object','bool', 'category']).drop(['graduated'], axis=1).columns\n",
    "X_selection_grad = selection_df.drop(columns=['graduated'])\n",
    "y_selection_grad = selection_df['graduated']\n",
    "preprocessor_grad = preprocess_pipeline(numeric_features, categorical_features_grad)\n",
    "X_selection_preprocessed_grad = preprocessor_grad.fit_transform(X_selection_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a list of all the columns after one hot encoding\n",
    "ohe_income = preprocessor_income['preprocessor'].named_transformers_['cat']['onehot']\n",
    "cat_processed_income = ohe_income.get_feature_names(X_selection_income[categorical_features_income].columns)\n",
    "all_processed_cols_income = np.concatenate((numeric_features, cat_processed_income), axis=0)\n",
    "\n",
    "ohe_grad = preprocessor_grad['preprocessor'].named_transformers_['cat']['onehot']\n",
    "cat_processed_grad = ohe_grad.get_feature_names(X_selection_grad[categorical_features_grad].columns)\n",
    "all_processed_cols_grad = np.concatenate((numeric_features, cat_processed_grad), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label: array([' - 50000.', ' 50000+.'], dtype='<U9')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f4390624b259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrfecv_income\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrfecv_income\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_selection_preprocessed_income\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_selection_income\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal number of features for Income: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrfecv_income\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max Score :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfecv_income\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    520\u001b[0m         scores = parallel(\n\u001b[1;32m    521\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m         scores = parallel(\n\u001b[1;32m    521\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     return rfe._fit(\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;31m# that have not been eliminated yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0msupport_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mranking_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(estimator, features)\u001b[0m\n\u001b[1;32m     31\u001b[0m     return rfe._fit(\n\u001b[1;32m     32\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 97\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1673\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1676\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: \"\n\u001b[0;32m-> 1246\u001b[0;31m                                      \"%r\" % (pos_label, present_labels))\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=1 is not a valid label: array([' - 50000.', ' 50000+.'], dtype='<U9')"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "### RFE CV to find best features \n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "rfecv_income = RFECV(clf, step=1, cv=5, scoring = 'recall')\n",
    "rfecv_income.fit(X_selection_preprocessed_income, y_selection_income)\n",
    "print(\"Optimal number of features for Income: %d\" % rfecv_income.n_features_)\n",
    "print(\"Max Score :\", max(rfecv_income.grid_scores_) )\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (% of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv_income.grid_scores_) + 1), rfecv_income.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### RFE CV to find best features \n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "rfecv_grad = RFECV(clf, step=1, cv=5, scoring = 'recall')\n",
    "rfecv_grad.fit(X_selection_preprocessed_grad, y_selection_grad)\n",
    "print(\"Optimal number of features for Graduated: %d\" % rfecv_grad.n_features_)\n",
    "print(\"Max Score :\", max(rfecv_grad.grid_scores_) )\n",
    "\n",
    "\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (% of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv_grad.grid_scores_) + 1), rfecv_grad.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show all selected features\n",
    "selected_features_income = all_processed_cols_income[rfecv_income.support_]\n",
    "selected_features_grad = all_processed_cols_grad[rfecv_grad.support_]\n",
    "print(selected_features_income)\n",
    "print(selected_features_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### log \n",
    "X_selection_log_income = X_selection_income.copy()\n",
    "X_selection_log_income['wage_per_hour'] = np.log10(X_selection_log_income['wage_per_hour'] + 1)\n",
    "X_selection_log_income['capital_gains'] = np.log10(X_selection_log_income['capital_gains'] + 1)\n",
    "X_selection_log_income['capital_losses'] = np.log10(X_selection_log_income['capital_losses'] + 1)\n",
    "X_selection_log_income['stock_dividends'] = np.log10(X_selection_log_income['stock_dividends'] + 1)\n",
    "X_selection_log_preprocessed_income = preprocessor_income.fit_transform(X_selection_log_income)\n",
    "\n",
    "X_selection_log_grad = X_selection_grad.copy()\n",
    "X_selection_log_grad['wage_per_hour'] = np.log10(X_selection_log_grad['wage_per_hour'] + 1)\n",
    "X_selection_log_grad['capital_gains'] = np.log10(X_selection_log_grad['capital_gains'] + 1)\n",
    "X_selection_log_grad['capital_losses'] = np.log10(X_selection_log_grad['capital_losses'] + 1)\n",
    "X_selection_log_grad['stock_dividends'] = np.log10(X_selection_log_grad['stock_dividends'] + 1)\n",
    "X_selection_log_preprocessed_grad = preprocessor_grad.fit_transform(X_selection_log_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(n_jobs=-1)\n",
    "rfecv_log_income = RFECV(clf, step=1, cv=5, scoring = 'recall')\n",
    "rfecv_log_income.fit(X_selection_log_preprocessed_income, y_selection_income)\n",
    "print(\"Optimal number of features for Income: %d\" % rfecv_log_income.n_features_)\n",
    "print(\"Max Score :\", max(rfecv_log_income.grid_scores_) )\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (% of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv_log_income.grid_scores_) + 1), rfecv_log_income.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(n_jobs=-1)\n",
    "rfecv_log_grad = RFECV(clf, step=1, cv=5, scoring = 'recall')\n",
    "rfecv_log_grad.fit(X_selection_log_preprocessed_grad, y_selection_grad)\n",
    "print(\"Optimal number of features for Graduated: %d\" % rfecv_log_grad.n_features_)\n",
    "print(\"Max Score :\", max(rfecv_log_grad.grid_scores_) )\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (% of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv_log_grad.grid_scores_) + 1), rfecv_log_grad.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show all selected features\n",
    "#index columns of sparse matrix\n",
    "X_selected_income = X_selection_preprocessed_income.tocsr()[:,rfecv_income.support_] \n",
    "X_selected_grad = X_selection_preprocessed_grad.tocsr()[:,rfecv_grad.support_] \n",
    "\n",
    "selected_features_income = all_processed_cols_income[rfecv_income.support_]\n",
    "selected_features_grad = all_processed_cols_grad[rfecv_grad.support_]\n",
    "\n",
    "print(selected_features_income)\n",
    "print(selected_features_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decision Tree for income\n",
    "classifier = DecisionTreeClassifier()\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth' : [2, None],\n",
    "    'min_samples_split' : [2, 3, 4],\n",
    "    'min_samples_leaf' : [1,2,3],\n",
    "    \n",
    "}\n",
    "\n",
    "CV_dt_income = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_dt_income.fit(X_selected_income, y_selection_income)\n",
    "    \n",
    "print('Best Score: {s}'.format(s=CV_dt_income.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_dt_income.best_params_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decision Tree for graduation\n",
    "classifier = DecisionTreeClassifier()\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth' : [2, None],\n",
    "    'min_samples_split' : [2, 3, 4],\n",
    "    'min_samples_leaf' : [1,2,3],\n",
    "    \n",
    "}\n",
    "\n",
    "CV_dt_grad = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_dt_grad.fit(X_selected_grad, y_selection_grad)\n",
    "    \n",
    "print('Best Score: {s}'.format(s=CV_dt_grad.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_dt_grad.best_params_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance graph\n",
    "#imp = dt_clf.feature_importances_\n",
    "\n",
    "#Plt\n",
    "#plt.bar(range(len(imp)),imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logistic Regression for income\n",
    "classifier = LogisticRegression()\n",
    "param_grid = { \n",
    "    'class_weight': ['balanced', None],\n",
    "    #'penalty' : ['l1', 'l2',],\n",
    "    'solver' : ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [99999],\n",
    "}\n",
    "\n",
    "CV_lr_income = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_lr_income.fit(X_selected_income, y_selection_income)\n",
    "    \n",
    "print('Best Score: {s}'.format(s=CV_lr_income.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_lr_income.best_params_)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logistic Regression for graduation\n",
    "classifier = LogisticRegression()\n",
    "param_grid = { \n",
    "    'class_weight': ['balanced', None],\n",
    "    #'penalty' : ['l1', 'l2',],\n",
    "    'solver' : ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [99999],\n",
    "}\n",
    "\n",
    "CV_lr_grad = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_lr_grad.fit(X_selected_grad, y_selection_grad)\n",
    "    \n",
    "print('Best Score: {s}'.format(s=CV_lr_grad.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_lr_grad.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### KNN for income\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "param_grid = { \n",
    "    'n_neighbors': [5, 10,100,200],\n",
    "}\n",
    "CV_knn_income = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_knn_income.fit(X_selected_income, y_selection_income)\n",
    "\n",
    "print('Best Score: {s}'.format(s=CV_knn_income.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_knn_income.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### KNN for graduation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "param_grid = { \n",
    "    'n_neighbors': [5, 10,100,200],\n",
    "}\n",
    "CV_knn_grad = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_knn_grad.fit(X_selected_grad, y_selection_grad)\n",
    "\n",
    "print('Best Score: {s}'.format(s=CV_knn_grad.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_knn_grad.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AdaBoost for income\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [.1, .5, 1],\n",
    "    'algorithm': ['SAMME.R', 'SAMME']\n",
    "}\n",
    "\n",
    "CV_ada_income = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_ada_income.fit(X_selected_income, y_selection_income)\n",
    "\n",
    "print('Best Score: {s}'.format(s=CV_ada_income.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_ada_income.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AdaBoost for graduation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [.1, .5, 1],\n",
    "    'algorithm': ['SAMME.R', 'SAMME']\n",
    "}\n",
    "\n",
    "CV_ada_grad = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_ada_grad.fit(X_selected_grad, y_selection_grad)\n",
    "\n",
    "print('Best Score: {s}'.format(s=CV_ada_grad.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_ada_grad.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Gradient Boosting for income\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate' : [0.001, 0.1, 0.5, 1],\n",
    "    'max_depth': [1,2,3],\n",
    "}\n",
    "\n",
    "classifier = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "\n",
    "CV_gbc_income = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_gbc_income.fit(X_selected_income, y_selection_income)\n",
    "\n",
    "print('Best Score: {s}'.format(s=CV_gbc_income.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_gbc_income.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Gradient Boosting for graduation\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate' : [0.001, 0.1, 0.5, 1],\n",
    "    'max_depth': [1,2,3],\n",
    "}\n",
    "\n",
    "classifier = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "\n",
    "CV_gbc_grad = GridSearchCV(classifier, param_grid, scoring='recall', cv=10, n_jobs= -1, np.random.seed(1))\n",
    "CV_gbc_grad.fit(X_selected_grad, y_selection_grad)\n",
    "\n",
    "print('Best Score: {s}'.format(s=CV_gbc_grad.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV_gbc_grad.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
