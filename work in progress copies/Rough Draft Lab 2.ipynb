{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Classification\n",
    "Group 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = [\n",
    "    'age',\n",
    "    'class_worker',\n",
    "    'det_ind_code',\n",
    "    'det_occ_code',\n",
    "    'education',\n",
    "    'wage_per_hour',\n",
    "    'hs_college',\n",
    "    'marital_stat',\n",
    "    'major_ind_code',\n",
    "    'major_occ_code',\n",
    "    'race',\n",
    "    'hisp_origin',\n",
    "    'sex',\n",
    "    'union_member',\n",
    "    'unemp_reason',\n",
    "    'full_or_part_emp',\n",
    "    'capital_gains',\n",
    "    'capital_losses',\n",
    "    'stock_dividends',\n",
    "    'tax_filer_stat',\n",
    "    'region_prev_res',\n",
    "    'state_prev_res',\n",
    "    'det_hh_fam_stat',\n",
    "    'det_hh_summ',\n",
    "    'instance_weight', ## this field is not used as a feature\n",
    "    'mig_chg_msa',\n",
    "    'mig_chg_reg',\n",
    "    'mig_move_reg',\n",
    "    'mig_same',\n",
    "    'mig_prev_sunbelt',\n",
    "    'num_emp',\n",
    "    'fam_under_18',\n",
    "    'country_father',\n",
    "    'country_mother',\n",
    "    'country_self',\n",
    "    'citizenship',\n",
    "    'own_or_self',\n",
    "    'vet_question',\n",
    "    'vet_benefits',\n",
    "    'weeks_worked',\n",
    "    'year',\n",
    "    'income_50k',\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/password1234/Documents/Machine Learning/census-income.data.csv', header=None, names=header_names)\n",
    "df_test = pd.read_csv('/Users/password1234/Documents/Machine Learning/census-income.test.csv', header=None, names=header_names)\n",
    "df = pd.concat([df,df_test]) ## the test file is also labelled so they can be merged\n",
    "df.drop(columns=['instance_weight']) ## not used for our analysis\n",
    "\n",
    "categorical_features = [\n",
    "    'class_worker',\n",
    "    'det_ind_code',\n",
    "    'det_occ_code',\n",
    "    'education',\n",
    "    'hs_college',\n",
    "    'marital_stat',\n",
    "    'major_ind_code',\n",
    "    'major_occ_code',\n",
    "    'race',\n",
    "    'hisp_origin',\n",
    "    'sex',\n",
    "    'union_member',\n",
    "    'unemp_reason',\n",
    "    'full_or_part_emp',\n",
    "    'tax_filer_stat',\n",
    "    'region_prev_res',\n",
    "    'state_prev_res',\n",
    "    'det_hh_fam_stat',\n",
    "    'det_hh_summ',\n",
    "    'mig_chg_msa',\n",
    "    'mig_chg_reg',\n",
    "    'mig_move_reg',\n",
    "    'mig_same',\n",
    "    'mig_prev_sunbelt',\n",
    "    'fam_under_18',\n",
    "    'country_father',\n",
    "    'country_mother',\n",
    "    'country_self',\n",
    "    'citizenship',\n",
    "    'own_or_self',\n",
    "    'vet_question',\n",
    "    'vet_benefits',\n",
    "    'year',\n",
    "]\n",
    "df[categorical_features] = df[categorical_features].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop columns not used in modelling\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        'region_prev_res',\n",
    "        'state_prev_res',\n",
    "        'det_hh_fam_stat',\n",
    "        'det_hh_summ',\n",
    "        'mig_chg_msa',\n",
    "        'mig_chg_reg',\n",
    "        'mig_move_reg',\n",
    "        'mig_same',\n",
    "        'mig_prev_sunbelt',\n",
    "        'country_father',\n",
    "        'country_mother',\n",
    "        'country_self',\n",
    "        'year',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is section one of the data processing, will be using the same data as shown in the minilab\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the dataset\n",
    "selection_df = df.sample(frac = .005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(numeric_features, categorical_features):\n",
    "    ### Scale numerical, one hot categorical\n",
    "\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            #('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ]\n",
    "    )\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)]\n",
    "    )\n",
    "    preprocess_pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocess_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess the data\n",
    "target = 'income_50k'\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object','bool', 'category']).drop([target], axis=1).columns\n",
    "X_selection = selection_df.drop(target, axis=1)\n",
    "y_selection = selection_df[target]\n",
    "preprocessor = preprocess_pipeline(numeric_features, categorical_features)\n",
    "X_selection_preprocessed = preprocessor.fit_transform(X_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a list of all the columns after one hot encoding\n",
    "ohe = preprocessor['preprocessor'].named_transformers_['cat']['onehot']\n",
    "cat_processed = ohe.get_feature_names(X_selection[categorical_features].columns)\n",
    "all_processed_cols = np.concatenate((numeric_features, cat_processed), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### RFE CV to find best features \n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "rfecv = RFECV(clf, step=1, cv=5)\n",
    "rfecv.fit(X_selection_preprocessed, y_selection)\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (% of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show all selected features\n",
    "selected_features = all_processed_cols[rfecv.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### log \n",
    "X_selection_log = X_selection.copy()\n",
    "X_selection_log['wage_per_hour'] = np.log10(X_selection_log['wage_per_hour'] + 1)\n",
    "X_selection_log['capital_gains'] = np.log10(X_selection_log['capital_gains'] + 1)\n",
    "X_selection_log['capital_losses'] = np.log10(X_selection_log['capital_losses'] + 1)\n",
    "X_selection_log['stock_dividends'] = np.log10(X_selection_log['stock_dividends'] + 1)\n",
    "X_selection_log_preprocessed = preprocessor.fit_transform(X_selection_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(n_jobs=-1)\n",
    "rfecv_log = RFECV(clf, step=1, cv=5)\n",
    "rfecv_log.fit(X_selection_log_preprocessed, y_selection)\n",
    "print(\"Optimal number of features : %d\" % rfecv_log.n_features_)\n",
    "print(\"Max Score :\", max(rfecv_log.grid_scores_) )\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (% of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv_log.grid_scores_) + 1), rfecv_log.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show all selected features\n",
    "selected_features = all_processed_cols[rfecv_log.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = selection_df[selected_features]\n",
    "\n",
    "finalDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using the classification_pipeline function Decision Tree\n",
    "classifier = DecisionTreeClassifier()\n",
    "param_grid = { \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth' : [2, None],\n",
    "    'min_samples_split' : [2, 3, 4],\n",
    "    'min_samples_leaf' : [1,2,3],\n",
    "    \n",
    "}\n",
    "\n",
    "CV = GridSearchCV(classifier, param_grid, scoring='accuracy', cv=10, n_jobs= -1)\n",
    "CV.fit(X_selected, y)\n",
    "    \n",
    "print('Best Score: {s}'.format(s=CV.best_score_))\n",
    "print('Best Parameters: {p}'.format(p=CV.best_params_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting prediction accuracy for Decision Tree\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion = 'gini', \n",
    "                                splitter = 'random', \n",
    "                                min_samples_split = 3, \n",
    "                                min_samples_leaf = 3)\n",
    "\n",
    "\n",
    "# train the decision tree algorithm\n",
    "%time dt_clf.fit(X_train,y_train)\n",
    "yhat = dt_clf.predict(X_test)\n",
    "print ('accuracy:', mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance graph\n",
    "imp = dt_clf.feature_importances_\n",
    "\n",
    "#Plt\n",
    "plt.bar(range(len(imp)), imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Evaluation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
